{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6407fe18-ed12-4b30-8e50-d985bf2845c9",
   "metadata": {},
   "source": [
    "# NOAA CO-OPS Data Download\n",
    "### Part 1 of 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1876eff-e19a-4e28-b10b-07c6a2e4dbbe",
   "metadata": {},
   "source": [
    "In this notebook, we will download atmospheric and water observations from the [National Oceanic and Atmospheric Administration](https://www.noaa.gov) (NOAA) [Center for Operational Oceanographic Products and Services](https://tidesandcurrents.noaa.gov/) (CO-OPS) data portal. The objective is to replicate the [Climatology for Virginia Key, FL](https://bmcnoldy.earth.miami.edu/vk/) page created and maintained by [Brian McNoldy](https://bmcnoldy.earth.miami.edu/) at the [University of Miami](https://welcome.miami.edu) [Rosenstiel School of Marine, Atmospheric, and Earth Science](http://earth.miami.edu).\n",
    "\n",
    "For sake of demonstration, we will focus on air and water temperature from Virginia Key, FL. Ultimately, however, there are several variables of interest:\n",
    "\n",
    "- Air temperature\n",
    "- Barometric pressure\n",
    "- Water temperature\n",
    "- Water level (*i.e.*, tides)\n",
    "- Wind speed\n",
    "\n",
    "This notebook will simply download the data, store the metadata, and write these to file. The second notebook, [NOAA-CO-OPS-records](NOAA-CO-OPS-records.ipynb), will filter these data and calculate a set of statistics and records. Part 3, [NOAA-CO-OPS-plots](NOAA-CO-OPS-plots.ipynb), will plot and display the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91869d0-521c-49d9-8806-7c7efb51918d",
   "metadata": {},
   "source": [
    "### Packages and configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04210715-0dbd-489c-b68d-857c31a2e7ec",
   "metadata": {},
   "source": [
    "First we import the packages we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0083e0b1-a8b1-4eb3-8640-d8cf83e41a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from noaa_coops import Station\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b20e29a-3ba4-4836-94d7-ebc233ec01d3",
   "metadata": {},
   "source": [
    "By default, Python only displays warnings the first time they are thrown. Ideally, we want a code that does not throw any warnings, but it sometimes takes soem trial and error to resolve the issue being warned about. So, for diagnostic purposes, we'll set the kernel to always display warnings.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1a29b10-a9ce-4ca6-8ffa-5795d554cc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('always')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b3c19e-41f5-45e5-a980-133f3434fc1d",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e473389e-3ab4-4abf-a46a-400235bf3835",
   "metadata": {},
   "source": [
    "Next, we define a number of functions that will come in handy later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c65df92-d97f-4424-8abd-0ceae78f02f3",
   "metadata": {},
   "source": [
    "#### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be76b3e3-7acb-4d9f-ac46-fb9395bcbceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def camel(text):\n",
    "    \"\"\"Convert 'text' to camel case\"\"\"\n",
    "    s = text.replace(',','').replace(\"-\", \" \").replace(\"_\", \" \")\n",
    "    s = s.split()\n",
    "    if len(text) == 0:\n",
    "        return text\n",
    "    return s[0].lower() + ''.join(i.capitalize() for i in s[1:])\n",
    "\n",
    "def get_units(variable, unit_system):\n",
    "    \"\"\"Return the desired units for 'variable'\"\"\"\n",
    "    unit_options = dict({\n",
    "        'Air Temperature': {'metric': 'C', 'english': 'F'},\n",
    "        'Barometric Pressure': {'metric': 'mb', 'english': 'mb'},\n",
    "        'Wind Speed': {'metric': 'm/s', 'english': 'kn'},\n",
    "        'Wind Gust': {'metric': 'm/s', 'english': 'kn'},\n",
    "        'Wind Direction': {'metric': 'deg', 'english': 'deg'},\n",
    "        'Water Temperature': {'metric': 'C', 'english': 'F'},\n",
    "        'Water Level': {'metric': 'm', 'english': 'ft'}\n",
    "    })\n",
    "    return unit_options[variable][unit_system]\n",
    "\n",
    "def format_date(datestr):\n",
    "    \"\"\"Format date strings into YYYYMMDD format\"\"\"\n",
    "    dtdt = pd.to_datetime(datestr)\n",
    "    return dt.datetime.strftime(dtdt, '%Y%m%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42a12a3-95c6-401d-878b-9836c2cf239d",
   "metadata": {},
   "source": [
    "#### Downloading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "791a6c4d-9f93-49d3-a5cc-5d4fedf61437",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_atemp(metadata, start_date, end_date, verbose=True):\n",
    "    \"\"\"Download air temperature data from NOAA CO-OPS between 'start_date'\n",
    "    and 'end_date' for 'stationid', 'unit_system', and timezone 'tz'\n",
    "    provided in 'metadata' dictionary.\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        print('Retrieving air temperature data')\n",
    "    station = Station(id=metadata['stationid'])\n",
    "    if not start_date:\n",
    "        start_date = format_date(station.data_inventory['Air Temperature']['start_date'])\n",
    "    if not end_date:\n",
    "        end_date = format_date(pd.to_datetime('today') + pd.Timedelta(days=1))\n",
    "    air_temp = station.get_data(\n",
    "        begin_date=start_date,\n",
    "        end_date=end_date,\n",
    "        product='air_temperature',\n",
    "        units=metadata['unit_system'],\n",
    "        time_zone=metadata['tz'])\n",
    "    air_temp.columns = ['atemp', 'atemp_flag']\n",
    "    return air_temp\n",
    "\n",
    "def load_wind(metadata, start_date, end_date, verbose=True):\n",
    "    \"\"\"Download wind data from NOAA CO-OPS between 'start_date' and\n",
    "    'end_date' for 'stationid', 'unit_system', and timezone 'tz' provided\n",
    "    in 'metadata' dictionary.\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        print('Retrieving wind data')\n",
    "    station = Station(id=metadata['stationid'])\n",
    "    if not start_date:\n",
    "        start_date = format_date(station.data_inventory['Wind']['start_date'])\n",
    "    if not end_date:\n",
    "        end_date = format_date(pd.to_datetime('today') + pd.Timedelta(days=1))\n",
    "    wind = station.get_data(\n",
    "        begin_date=start_date,\n",
    "        end_date=end_date,\n",
    "        product='wind',\n",
    "        units=metadata['unit_system'],\n",
    "        time_zone=metadata['tz'])\n",
    "    wind.columns = ['windspeed', 'winddir_deg', 'winddir',\n",
    "                    'windgust', 'wind_flag']\n",
    "    return wind\n",
    "\n",
    "def load_atm_pres(metadata, start_date, end_date, verbose=True):\n",
    "    \"\"\"Download barometric pressure data from NOAA CO-OPS between\n",
    "    'start_date' and 'end_date' for 'stationid', 'unit_system', and\n",
    "    timezone 'tz' provided in 'metadata' dictionary.\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        print('Retrieving barometric pressure data')\n",
    "    station = Station(id=metadata['stationid'])\n",
    "    if not start_date:\n",
    "        start_date = format_date(station.data_inventory['Barometric Pressure']['start_date'])\n",
    "    if not end_date:\n",
    "        end_date = format_date(pd.to_datetime('today') + pd.Timedelta(days=1))\n",
    "    pressure = station.get_data(\n",
    "        begin_date=start_date,\n",
    "        end_date=end_date,\n",
    "        product='air_pressure',\n",
    "        units=metadata['unit_system'],\n",
    "        time_zone=metadata['tz'])\n",
    "    pressure.columns = ['apres', 'apres_flag']\n",
    "    return pressure\n",
    "\n",
    "def load_water_temp(metadata, start_date, end_date, verbose=True):\n",
    "    \"\"\"Download water temperature data from NOAA CO-OPS between\n",
    "    'start_date' and 'end_date' for 'stationid', 'unit_system', and\n",
    "    timezone 'tz' provided in 'metadata' dictionary.\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        print('Retrieving water temperature data')\n",
    "    station = Station(id=metadata['stationid'])\n",
    "    if not start_date:\n",
    "        start_date = format_date(station.data_inventory['Water Temperature']['start_date'])\n",
    "    if not end_date:\n",
    "        end_date = format_date(pd.to_datetime('today') + pd.Timedelta(days=1))\n",
    "    water_temp = station.get_data(\n",
    "        begin_date=start_date,\n",
    "        end_date=end_date,\n",
    "        product='water_temperature',\n",
    "        units=metadata['unit_system'],\n",
    "        time_zone=metadata['tz'])\n",
    "    water_temp.columns = ['wtemp', 'wtemp_flag']\n",
    "    return water_temp\n",
    "\n",
    "def load_water_level(metadata, start_date, end_date, verbose=True):\n",
    "    \"\"\"Download water level data from NOAA CO-OPS between 'start_date' and\n",
    "    'end_date' for 'stationid', 'unit_system', 'datum', and timezone 'tz'\n",
    "    provided in 'metadata' dictionary.\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        print('Retrieving water level tide data')\n",
    "    station = Station(id=metadata['stationid'])\n",
    "    if not start_date:\n",
    "        start_date = format_date(station.data_inventory['Verified 6-Minute Water Level']['start_date'])\n",
    "    if not end_date:\n",
    "        end_date = format_date(pd.to_datetime('today') + pd.Timedelta(days=1))\n",
    "    water_levels = station.get_data(\n",
    "        begin_date=start_date,\n",
    "        end_date=end_date,\n",
    "        product='water_level',\n",
    "        datum=metadata['datum'],\n",
    "        units=metadata['unit_system'],\n",
    "        time_zone=metadata['tz'])\n",
    "    water_levels.columns = ['wlevel', 's', 'wlevel_flag', 'wlevel_qc']\n",
    "    return water_levels\n",
    "\n",
    "def download_data(metadata, start_date=None, end_date=None, verbose=True):\n",
    "    \"\"\"Download data from NOAA CO-OPS\"\"\"\n",
    "    # List of data variables to combine at the end\n",
    "    datasets = []\n",
    "            \n",
    "    # If no 'end_date' is passed, download through end of current date\n",
    "    if not end_date:\n",
    "        end_date = format_date(pd.to_datetime('today') + pd.Timedelta(days=1))\n",
    "    \n",
    "    # Air temperature\n",
    "    if 'Air Temperature' in metadata['variables']:\n",
    "        air_temp = load_atemp(metadata=metadata, start_date=start_date,\n",
    "                              end_date=end_date, verbose=verbose)\n",
    "        air_temp['atemp_flag'] = air_temp['atemp_flag'].str.split(',', expand=True).astype(int).sum(axis=1)\n",
    "        air_temp.loc[air_temp['atemp_flag'] > 0, 'atemp'] = np.nan\n",
    "        datasets.append(air_temp['atemp'])\n",
    "\n",
    "    # Barometric pressure\n",
    "    if 'Barometric Pressure' in metadata['variables']:\n",
    "        pressure = load_atm_pres(metadata=metadata, start_date=start_date,\n",
    "                                 end_date=end_date, verbose=verbose)\n",
    "        pressure['apres_flag'] = pressure['apres_flag'].str.split(',', expand=True).astype(int).sum(axis=1)\n",
    "        pressure.loc[pressure['apres_flag'] > 0, 'apres'] = np.nan\n",
    "        datasets.append(pressure['apres'])\n",
    "\n",
    "    # Wind\n",
    "    if 'Wind Speed' in metadata['variables']:\n",
    "        metadata['variables'].extend(['Wind Gust'])\n",
    "        wind = load_wind(metadata=metadata, start_date=start_date,\n",
    "                         end_date=end_date, verbose=verbose)\n",
    "        wind['windflag'] = wind['wind_flag'].str.split(',', expand=True).astype(int).sum(axis=1)\n",
    "        wind.loc[wind['wind_flag'] > 0, ['windspeed', 'windgust']] = np.nan\n",
    "        datasets.append(wind[['windspeed', 'windgust']])\n",
    "\n",
    "    # Water temperature\n",
    "    if 'Water Temperature' in metadata['variables']:\n",
    "        water_temp = load_water_temp(metadata=metadata, start_date=start_date,\n",
    "                                     end_date=end_date, verbose=verbose)\n",
    "        water_temp['wtemp_flag'] = water_temp['wtemp_flag'].str.split(',', expand=True).astype(int).sum(axis=1)\n",
    "        water_temp.loc[water_temp['wtemp_flag'] > 0, 'wtemp'] = np.nan\n",
    "        datasets.append(water_temp['wtemp'])\n",
    "\n",
    "    # Water level (tides)\n",
    "    if 'Verified 6-Minute Water Level' in metadata['variables']:\n",
    "        water_levels = load_water_level(metadata=metadata, start_date=start_date,\n",
    "                                        end_date=end_date, verbose=verbose)\n",
    "        water_levels['wlevel_flag'] = water_levels['wlevel_flag'].str.split(',', expand=True).astype(int).sum(axis=1)\n",
    "        water_levels.loc[water_levels['wlevel_flag'] > 0, 'wlevel'] = np.nan\n",
    "        datasets.append(water_levels['wlevel'])\n",
    "\n",
    "    # Merge into single dataframe and rename columns\n",
    "    newdata = pd.concat(datasets, axis=1)\n",
    "    newdata.index.name = f'time_{metadata[\"tz\"]}'\n",
    "    newdata.columns = [i for i in metadata['variables']]\n",
    "    return newdata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20db6640-a7e4-4549-b3ee-849b117715bf",
   "metadata": {},
   "source": [
    "### Load / download data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d604ab3f-732a-45e9-b72a-8c8c19fb58a9",
   "metadata": {},
   "source": [
    "Now it's time to load the data. First, specify the station we want to load. This will be used to load saved data or download all data from a new station, if we have not yet retrieved data from this particular `stationname`.\n",
    "\n",
    "`stationname` is a custom human-readable \"City, ST\" string for the station, while `id` is the NOAA-COOPS station ID number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a528859-8acb-4069-a3d2-9b1ddb29ef08",
   "metadata": {},
   "outputs": [],
   "source": [
    "stationname = 'Virginia Key, FL'\n",
    "id = '8723214'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a0d94e-b52d-47e8-bebb-d40b55bd8fab",
   "metadata": {},
   "source": [
    "Derive the directory name containing for data from the station name. This is where the data are or will be saved locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca70399f-6e73-4944-a89f-eb9e3c51e4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Station folder: virginiaKeyFl\n",
      "Full directory: /home/climatology/virginiaKeyFl\n"
     ]
    }
   ],
   "source": [
    "dirname = camel(stationname)\n",
    "outdir = os.path.join(os.getcwd(), dirname)\n",
    "\n",
    "print(f\"Station folder: {dirname}\")\n",
    "print(f\"Full directory: {outdir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b99ebe4-4d23-4d85-b8ea-9f5b4be39b52",
   "metadata": {},
   "source": [
    "Flag for printing statuses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0266df44-d651-4114-9120-eb2e71a4bf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0d2fc2-64e1-48a4-9571-4e4d93150045",
   "metadata": {},
   "source": [
    "Let's see if we already have data from this station saved locally. This will be true if a directory already exists for the station.\n",
    "\n",
    "If the directory `outdir` does not exist, then no data have been downloaded for this station, so we need to download everything through the present. This requires a few steps:\n",
    "\n",
    "1. Create `outdir`\n",
    "2. Load the configuration settings from `station-init.yml`. This file contains settings such as unit system, time zone, and what variables to retrieve. Using a init file like this makes it easier to keep the same settings across multiple stations. It will be read in as a Python dictionary, which we will call `meta` and will use to store all relevant metadata for the station.\n",
    "3. Download the data and record the timestamp of the last observation in the metadata. This will be used later when updating the data.\n",
    "4. Write the data and metadata to file.\n",
    "\n",
    "On the other hand, if data already exist locally, we will load it from file and download new data we do not yet have:\n",
    "\n",
    "1. Load the data and metadata from file\n",
    "2. Retrieve new data\n",
    "3. Combine new data to existing data, update the 'last_updated' metadata entry, and write data and metadata to file\n",
    "\n",
    "The noaa-coops tool only accepts dates without times, so it is possible to download data we already have. We therefore have to check what we download against what we already have to avoid duplicating data.\n",
    "\n",
    "The most likely (and perhaps only) scenerio is if the data we have for the most recent day is incomplete. For example, assume today is May 5, 2024 and we download data at noon. Also assume the start date is some earlier day, the last time we retrieved data, and this will be automatically determined from the metadata. Specifying an end date `2024-05-01` will retrieve all data available through noon on May 5. In this case, we do not yet have these data, so we concatenate what we do not have to what we do have. However, if we then run the download function again (say, for diagnostic purposes) with the new start date of `2024-05-01` and the end date `2024-05-01`, it will again download the data through noon on May 5. But since we already have those data, we do not want to re-concatenate them.\n",
    "\n",
    "*This cell may take several seconds or minutes to run, depending on how much data is being downloaded.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e77b9030-b586-4a20-85d0-ba71d1bde218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading metadata from file\n",
      "Loading data from file\n",
      "Retrieving air temperature data\n",
      "Retrieving water temperature data\n",
      "No new data available.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(outdir):\n",
    "    if verbose:\n",
    "        print('Creating new directory for this station.')\n",
    "    os.makedirs(outdir)\n",
    "\n",
    "    # Metadata configuration\n",
    "    with open('station-init.yml') as d:\n",
    "        meta = yaml.safe_load(d)\n",
    "    meta['units'] = {k:get_units(k, meta['unit_system']) for k in meta['variables']}\n",
    "    meta['outdir'] = outdir\n",
    "    meta['stationname'] = stationname\n",
    "    meta['stationid'] = id\n",
    "\n",
    "    # Download all data (set start and end date to None to get all data)\n",
    "    if verbose:\n",
    "        print('Downloading all data for this station.')\n",
    "    data = download_data(metadata=meta, start_date=None, end_date=None)\n",
    "    data.to_csv(os.path.join(meta['outdir'], 'observational_data_record.csv.gz'),\n",
    "                             compression='infer')\n",
    "    print(\"Updated observational data written to file \"\\\n",
    "          f\"{os.path.join(meta['outdir'], 'observational_data_record.csv')}.\")\n",
    "\n",
    "    # Save metadata\n",
    "    meta['last_updated'] = str(data.index.max())\n",
    "    if verbose:\n",
    "        print(f\"Metadata written to file {os.path.join(meta['outdir'], 'metadata.yml')}\")\n",
    "    with open(os.path.join(meta['outdir'], 'metadata.yml'), 'w') as fp:\n",
    "        yaml.dump(meta, fp)\n",
    "    \n",
    "else:\n",
    "    # Load the metadata\n",
    "    if verbose:\n",
    "        print('Loading metadata from file')\n",
    "    with open(os.path.join(outdir, 'metadata.yml')) as m:\n",
    "        meta = yaml.safe_load(m)\n",
    "    \n",
    "    # Load the historical data\n",
    "    if verbose:\n",
    "        print('Loading data from file')\n",
    "    data = pd.read_csv(os.path.join(outdir, 'observational_data_record.csv.gz'),\n",
    "                       index_col=f'time_{meta[\"tz\"]}', parse_dates=True,\n",
    "                       compression='infer')\n",
    "\n",
    "    # Retrieve new data\n",
    "    newdata = download_data(metadata=meta, start_date=format_date(meta['last_updated']))\n",
    "    if sum(~newdata.index.isin(data.index)) == 0:\n",
    "        print('No new data available.')\n",
    "    else:\n",
    "        data = pd.concat([data,\n",
    "                          newdata[newdata.index.isin(data.index) == False]], axis=0)\n",
    "        data.to_csv(os.path.join(meta['outdir'], 'observational_data_record.csv.gz'),\n",
    "                                 compression='infer')\n",
    "        meta['last_updated'] = str(data.index.max())\n",
    "        with open(os.path.join(meta['outdir'], 'metadata.yml'), 'w') as fp:\n",
    "            yaml.dump(meta, fp)\n",
    "        print(\"Updated observational data written to file \"\\\n",
    "              f\"{os.path.join(meta['outdir'], 'observational_data_record.csv')}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09a4e80-cf5e-44e3-b7fc-e3d8ff343ca7",
   "metadata": {},
   "source": [
    "Check the data and metadata for sanity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b196a01e-3e72-4473-a957-0ce11334a96b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Air Temperature</th>\n",
       "      <th>Water Temperature</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_lst</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1994-01-28 00:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994-01-28 00:06:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994-01-28 00:12:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994-01-28 00:18:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994-01-28 00:24:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-25 09:36:00</th>\n",
       "      <td>83.5</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-25 09:42:00</th>\n",
       "      <td>83.5</td>\n",
       "      <td>86.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-25 09:48:00</th>\n",
       "      <td>83.7</td>\n",
       "      <td>86.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-25 09:54:00</th>\n",
       "      <td>83.8</td>\n",
       "      <td>86.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-25 10:00:00</th>\n",
       "      <td>83.7</td>\n",
       "      <td>86.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2466580 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Air Temperature  Water Temperature\n",
       "time_lst                                               \n",
       "1994-01-28 00:00:00              NaN                NaN\n",
       "1994-01-28 00:06:00              NaN                NaN\n",
       "1994-01-28 00:12:00              NaN                NaN\n",
       "1994-01-28 00:18:00              NaN                NaN\n",
       "1994-01-28 00:24:00              NaN                NaN\n",
       "...                              ...                ...\n",
       "2024-05-25 09:36:00             83.5               86.0\n",
       "2024-05-25 09:42:00             83.5               86.2\n",
       "2024-05-25 09:48:00             83.7               86.2\n",
       "2024-05-25 09:54:00             83.8               86.2\n",
       "2024-05-25 10:00:00             83.7               86.2\n",
       "\n",
       "[2466580 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5aaa907c-69e8-4434-92a7-e40f63932a0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'datum': 'MHHW',\n",
       " 'day_threshold': 2,\n",
       " 'hr_threshold': 3,\n",
       " 'last_updated': '2024-05-25 10:00:00',\n",
       " 'outdir': '/home/climatology/virginiaKeyFl',\n",
       " 'stationid': '8723214',\n",
       " 'stationname': 'Virginia Key, FL',\n",
       " 'tz': 'lst',\n",
       " 'unit_system': 'english',\n",
       " 'units': {'Air Temperature': 'F', 'Water Temperature': 'F'},\n",
       " 'variables': ['Air Temperature', 'Water Temperature']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fc50ac9-fa54-47c4-b7f3-4231c7d0092d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.index.unique()) == data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80a43a7-6fa4-4800-87f1-794ac5470dc2",
   "metadata": {},
   "source": [
    "The 'last_updated' metadata flag matches the last observation in the data record and corresponds to the most recently available observation. Also, every observation time is unique, so there are no duplicated entries. So, everything checks out.\n",
    "\n",
    "In the next part, [NOAA-CO-OPS-records](NOAA-CO-OPS-records.ipynb), we will clean filter these data and calculate statistics and records."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f630e198-4ab8-45e9-a18e-046c2980eaa5",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
